{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSiba/ColabRepo/blob/main/regressor_pwngc_index_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Checks"
      ],
      "metadata": {
        "id": "yG45YqPiOwtZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TerminalIPythonApp] WARNING | Subcommand `ipython kernelspec` is deprecated and will be removed in future versions.\n",
            "[TerminalIPythonApp] WARNING | You likely want to use `jupyter kernelspec` in the future\n",
            "Available kernels:\n",
            "  ir         /usr/local/share/jupyter/kernels/ir\n",
            "  python3    /usr/local/share/jupyter/kernels/python3\n",
            "3.7.13 (default, Mar 16 2022, 17:37:17) \n",
            "[GCC 7.5.0]\n",
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "# Some checks\n",
        "\n",
        "!ipython kernelspec list\n",
        "import sys\n",
        "print(sys.version)\n",
        "print(sys.executable)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RojggxQzYM9F",
        "outputId": "471f143e-5b93-49af-e73b-7da0ce4a9fb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numba"
      ],
      "metadata": {
        "id": "E3osdH6pxxp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install bcolz"
      ],
      "metadata": {
        "id": "jHQwxgQ9YjWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/extended_omw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2021.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ],
      "source": [
        "# Imports \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import nn, Tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import math\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "#import bcolz\n",
        "\n",
        "import time\n",
        "import random\n",
        "import functools\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"all\")\n",
        "# nltk.download(\"stopwords\")\n",
        "# nltk.download(\"punkt\")\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from nltk import pos_tag, WordNetLemmatizer\n",
        "from pprint import pprint\n",
        "import string\n",
        "\n",
        "import bz2\n",
        "import pickle\n",
        "import _pickle as cPickle\n",
        "\n",
        "import numba\n",
        "from numba import jit\n",
        "from numba import njit\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use('seaborn')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er22_9ilYM9I",
        "outputId": "5ff5d161-630d-4458-edeb-381d3f5d0d8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axg3vWr_YsZM",
        "outputId": "d1e4eaf1-ac0c-4774-cab9-b834b92a1ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# set seed to ensure the same initialization for every run\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IZ2DJA3vYM9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89544695-d27e-4f4d-8796-456f8174f0a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To prevent Colab from disconnection\n",
        "# while True:pass"
      ],
      "metadata": {
        "id": "rkdoYU92V4dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "UuYOEKv_V_oT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils Functions (Loading Data, Vocab, Numericalization, Input Preprocessing, Tag Decoding)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "AaNWxx1ZYM9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def to_tensor(string_list):\n",
        "    l_str = []\n",
        "    for ele in string_list:\n",
        "        if ele[0] == \"[\":\n",
        "            l_str.append(ele[1:])\n",
        "        else:\n",
        "            if ele[-1] == \"]\":\n",
        "                l_str.append(ele[:-1])\n",
        "            else:\n",
        "                l_str.append(ele)\n",
        "\n",
        "    str_vec = \" \".join(l_str)\n",
        "    torch_labels = torch.tensor(list(map(float, str_vec.split(' '))), dtype=torch.float32)\n",
        "    return torch_labels"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UwR3TRG1YM9L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def parse_data(file):\n",
        "    \"\"\"\n",
        "    reads the stem word and the spatial tag of each token in the .csv file\n",
        "    :param corpus_file:\n",
        "    :param datafields:\n",
        "    :return: List of training data of the form [[tokenized_sentence-1, spatial_tensors],\n",
        "                                                [tokenized_sentence-1, spatial_tensors], ...]\n",
        "    \"\"\"\n",
        "    with open(file, encoding='utf-8') as f:\n",
        "        examples = []\n",
        "        words = []\n",
        "        lemmas = []\n",
        "        synset_offset = []\n",
        "        idx = []\n",
        "        labels = []\n",
        "        for line in f:\n",
        "            # print(\"initial line \", line)\n",
        "            line = line.strip()\n",
        "            # print(\"STRIPPING line \", line)\n",
        "            if not line:\n",
        "                examples.append([lemmas, synset_offset, labels, idx])\n",
        "                words = []\n",
        "                lemmas = []\n",
        "                synset_offset = []\n",
        "                idx = []\n",
        "                labels = []\n",
        "            else:\n",
        "                columns = line.split()\n",
        "                # print(\"cols\", columns)\n",
        "                words.append(columns[0])\n",
        "                lemmas.append(columns[1])\n",
        "                synset_offset.append(columns[4])\n",
        "                idx.append(int(columns[5]))\n",
        "                lab = to_tensor(columns[-6:])\n",
        "                labels.append(lab)\n",
        "\n",
        "               \n",
        "\n",
        "        return examples"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "N3g38XKKYM9L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def clean_untagged(data):\n",
        "    original_data = data\n",
        "    for entry in data:\n",
        "        \n",
        "        idx = [i for i, syn in enumerate(entry[1]) if syn == 'no-synset']\n",
        "\n",
        "        # remove those from the data\n",
        "        for s in reversed(idx):\n",
        "            del entry[0][s]\n",
        "            del entry[1][s]\n",
        "            del entry[2][s]\n",
        "\n",
        "    return original_data, data"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nNzbOazAYM9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def data_id(data):\n",
        "\n",
        "    # data_collector = {\"0\": [[], []], \"1\": [[],[]], ...}\n",
        "    data_collector = {}\n",
        "    for i, instance in enumerate(data):\n",
        "        data_collector[str(i)] = instance\n",
        "\n",
        "    return data_collector"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3gUGwUHKYM9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_vocab(data, embed_size=300):\n",
        "\n",
        "    data = list(data)\n",
        "    \n",
        "    # insert all dataset vocabulary\n",
        "    dataset_vocab = []\n",
        "    \n",
        "    print(data[0])\n",
        "    if isinstance(data[0], str):\n",
        "        dataset_vocab = data\n",
        "    else:\n",
        "        for instance in data:            \n",
        "            dataset_vocab += instance[0]\n",
        "        \n",
        "    # print(len(dataset_vocab))\n",
        "    \n",
        "    # remove duplicates\n",
        "    target_vocab = set(dataset_vocab)\n",
        "    \n",
        "    # generate weights matrix using glove\n",
        "    matrix_len = len(target_vocab)\n",
        "    \n",
        "    weights_matrix = np.zeros((matrix_len, embed_size))\n",
        "    \n",
        "    words_found = 0\n",
        "\n",
        "    for i, word in enumerate(target_vocab):\n",
        "        #print(i, word)\n",
        "        try:\n",
        "            weights_matrix[i] = glove[word]\n",
        "            #print(weights_matrix[i])\n",
        "            words_found += 1\n",
        "        except KeyError:\n",
        "            weights_matrix[i] = np.random.normal(scale=0.6, size=(embed_size, ))\n",
        "            #print(weights_matrix[i])\n",
        "    #print(words_found)\n",
        "    \n",
        "    return target_vocab, weights_matrix"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0ucyBqVlYM9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def numericalize(tokens_list, vocab):\n",
        "    \n",
        "    str2num = {word: index for index, word in enumerate(vocab)}\n",
        "    num_list = []\n",
        "    for token in tokens_list:\n",
        "        num_list.append(str2num[token])\n",
        "        \n",
        "    return torch.tensor(num_list, dtype=torch.long)\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wenA6SRyYM9O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Preprocess Input sentence\n",
        "\n",
        "# set of english stop words U set of punctuation\n",
        "EN_STOPWORDS_PUNCT = set(stopwords.words('english')).union(set(string.punctuation))\n",
        "WN_LEMMATIZER = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def tags4wn(tag):\n",
        "    \"\"\"Penn Treebank tags: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
        "    Converts PennTreeBank tags to WN tags, e.g. n, a, v\"\"\"\n",
        "    tag_conversion = {\"NN\": \"n\", # noun\n",
        "                      \"JJ\": \"a\", # adjective\n",
        "                      \"VB\": \"v\", # verb\n",
        "                      \"RB\": \"r\"} # adverb\n",
        "    # there are still many more tags\n",
        "    try:\n",
        "        # return the WN tags\n",
        "        return tag_conversion[tag[:2]]\n",
        "    except:\n",
        "        # if no tag is found, treat the word as a noun\n",
        "        return \"n\"\n",
        "        # I think that in our case it is better to consider them all\n",
        "        # return None\n",
        "\n",
        "def preprocess(sentence):\n",
        "    \"\"\"Preprocesses a raw input sentence and return a list of each word with its POS tag.\"\"\"\n",
        "    # Tokenization\n",
        "    tokenized_sentence = nltk.word_tokenize(sentence)\n",
        "    # lowercase all words\n",
        "    lower = [word.lower() for word in tokenized_sentence]\n",
        "    # print(lower)\n",
        "    # delete stop words and punctuation\n",
        "    clean_sentence = [word for word in lower if word not in EN_STOPWORDS_PUNCT]\n",
        "    # print(clean_sentence)\n",
        "    # use wordNet Lemmatizer to do POS and then lemmatize\n",
        "    pos_tagging = pos_tag(clean_sentence)\n",
        "    # print(pos_tagging)\n",
        "    # Lemmatize\n",
        "    lemmatized_sentence = [(WN_LEMMATIZER.lemmatize(word, pos=tags4wn(tag)), tags4wn(tag)) for word, tag in pos_tagging]\n",
        "    # print(lemmatized_sentence)\n",
        "\n",
        "    return lemmatized_sentence\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_xVEpzceYM9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_tag(tokens, sentag_idx, sentag_dist):\n",
        "    print(f\"token:8s | kind:4s | top_k:4s | dist:4s\")\n",
        "    print()\n",
        "    for t, i, d in zip(tokens, sentag_idx, sentag_dist):\n",
        "      for (ik, iv), (dk, dv) in zip(i.items(), d.items()):\n",
        "        \n",
        "          # decode fct\n",
        "          #print(\"B = partially overlaping\")\n",
        "          #print(ik, dk)\n",
        "          iv, dv = iv.cpu().detach().numpy(), dv.cpu().detach().numpy()\n",
        "          senses, distances = target_VOCAB[iv], dv\n",
        "          #print(senses, distances)\n",
        "          for sense, distance in zip(senses, distances):\n",
        "              print(f'{t:8s}, {ik:4s}, {sense:4s}, {distance:4s}')\n",
        "          print()\n",
        "          print()"
      ],
      "metadata": {
        "id": "ysrHv73MEtCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "JXSQufUkYM9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "quHX2Q3SZ2-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49ff4e7-6be2-4769-a5af-1f03683f1d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training on PWNGC (only)"
      ],
      "metadata": {
        "id": "XVnUQgeYvXSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resources_path = \"/content/drive/MyDrive/ColabNotebooks/wsd_resources/resources_factory\"\n",
        "pwngc_path = \"/pwngc\"\n",
        "train_path_pwngc = \"/idx_complete_pwngc4regressor.csv\"\n",
        "resources_path + pwngc_path + train_path_pwngc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oxRS52zYuOiX",
        "outputId": "81508910-9852-4dfe-cc30-d6ca8b55d171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/ColabNotebooks/wsd_resources/resources_factory/pwngc/idx_complete_pwngc4regressor.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- do it once"
      ],
      "metadata": {
        "id": "L6PSPtIAvhvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # parse training data through path\n",
        "data = parse_data(resources_path + pwngc_path + train_path_pwngc)"
      ],
      "metadata": {
        "id": "1MkQDNifvebw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCL63vfyAdf6",
        "outputId": "9a9be91c-8198-459b-c66a-03bb5269ced0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186655"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty_entries = 0\n",
        "for entry in data:\n",
        "  if entry == [[], [], [], []]:\n",
        "    empty_entries +=1 \n",
        "\n",
        "print(empty_entries) # 939"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYVUeuZ1-vhh",
        "outputId": "04362fb0-a7f5-4058-e700-ed3281ef031a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(filter(([[], [], [], []]).__ne__, data))"
      ],
      "metadata": {
        "id": "JWum2gjRAW14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "388L89oTAw1T",
        "outputId": "3f19c8fc-cc0a-4fe1-f432-fcaa0953130c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "185716"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetID = data_id(data)"
      ],
      "metadata": {
        "id": "xA099-2C_vIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # store the dataset arranged by ID in a .pt file\n",
        "# # Saving and loading data to/from .pt\n",
        "# # save\n",
        "torch.save(datasetID, resources_path + pwngc_path + \"/indexed_pwngc_id.pt\")\n"
      ],
      "metadata": {
        "id": "__xqqkHpADxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- restart from here"
      ],
      "metadata": {
        "id": "4swbnCh2Cc7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasetID = torch.load(resources_path + pwngc_path + \"/indexed_pwngc_id.pt\")"
      ],
      "metadata": {
        "id": "f4X2mjZ8CfpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# partition data in training/validation\n",
        "splittings = {}"
      ],
      "metadata": {
        "id": "oa1Zf3BLCpEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split training and validation data by ID\n",
        "\n",
        "S = len(datasetID.keys())\n",
        "N_train = int(S * 95 / 100)\n",
        "N_valid = int(S * 5 / 100)\n",
        "# N_test = 5\n",
        "N_train, N_valid\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6eXNB_DDj7p",
        "outputId": "7568ad1e-3029-4815-d927-c3b2060c1a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(176430, 9285)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# choose N training instances, randomly!\n",
        "splittings[\"train\"] = random.sample(list(datasetID), N_train)\n",
        "splittings[\"validate\"] = random.sample(list(set(datasetID) - set(splittings[\"train\"])), N_valid)\n"
      ],
      "metadata": {
        "id": "sKaH9wE4GnAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, list_ids, path2data):\n",
        "        super().__init__()\n",
        "\n",
        "        self.list_ids = list_ids\n",
        "        self.path2data = path2data\n",
        "        self.dataset = torch.load(self.path2data)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"Total Number of samples.\"\n",
        "\n",
        "        return len(self.list_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"Extracts one Example of data.\"\n",
        "\n",
        "        id = self.list_ids[index]\n",
        "        \n",
        "\n",
        "        # data\n",
        "        X = self.dataset[id][0]\n",
        "        tag_y = self.dataset[id][1]\n",
        "        y = self.dataset[id][2]\n",
        "        idx_y = self.dataset[id][3]\n",
        "\n",
        "        return X, y, tag_y, idx_y"
      ],
      "metadata": {
        "id": "m9F0cjOwHwu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ❌ Do it only once"
      ],
      "metadata": {
        "id": "owbftETCr1eR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# parse training data through path\n",
        "# data = parse_data(path + train_path)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "k2266Q4CYM9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# clean parsed data\n",
        "# orig, data = clean_untagged(data)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "H9ckBuRTYM9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# create for each entry in dataset an ID\n",
        "# datasetID = data_id(data)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "By01nWG5YM9R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# store the dataset arranged by ID in a .pt file\n",
        "# Saving and loading data to/from .pt\n",
        "# save\n",
        "# torch.save(datasetID, path + \"pwngc_id.pt\")\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1vdxDAcLYM9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ❌ restart from here: "
      ],
      "metadata": {
        "collapsed": false,
        "id": "iZsdSJmaYM9R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# datasetID = torch.load(path + \"pwngc_id.pt\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9Gj_lpJZYM9S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# # partition data in training/validation\n",
        "# splittings = {}\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ffDJf1CWYM9S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# # split training and validation data by ID\n",
        "\n",
        "# N_train = 10\n",
        "# N_valid = 5\n",
        "# N_test = 5\n",
        "# # choose N training instances, randomly!\n",
        "# splittings[\"train\"] = random.sample(list(datasetID), N_train)\n",
        "# splittings[\"validate\"] = random.sample(list(set(datasetID) - set(splittings[\"train\"])), N_valid)\n",
        "# # splittings"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PoV57yfXYM9T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# # Dataset\n",
        "# class Dataset(torch.utils.data.Dataset):\n",
        "    \n",
        "#     def __init__(self, list_ids, path2data):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.list_ids = list_ids\n",
        "#         self.path2data = path2data\n",
        "#         self.dataset = torch.load(self.path2data)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         \"Total Number of samples.\"\n",
        "\n",
        "#         return len(self.list_ids)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         \"Extracts one Example of data.\"\n",
        "\n",
        "#         id = self.list_ids[index]\n",
        "        \n",
        "\n",
        "#         # data\n",
        "#         X = self.dataset[id][0]\n",
        "#         tag_y = self.dataset[id][1]\n",
        "#         y = self.dataset[id][2]\n",
        "\n",
        "#         return X, y, tag_y"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "b39060PEYM9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading Glove"
      ],
      "metadata": {
        "collapsed": false,
        "id": "EkIQUo3sYM9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "glove_path = \"/content/drive/MyDrive/ColabNotebooks/wsd_resources/glove/\""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vsx5ohK-YM9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2195846\n"
          ]
        }
      ],
      "source": [
        "# decompress the pkl file\n",
        "glove_comp = glove_path + '840B.300_glove.pkl' + '.pbz2'\n",
        "bz2_data = bz2.BZ2File(glove_comp, 'rb')\n",
        "glove = cPickle.load(bz2_data)\n",
        "\n",
        "#glove = pickle.load(open(f'{glove_path}/840B.300_glove.pkl', 'rb'))\n",
        "print(len(glove))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWprbK9lYM9U",
        "outputId": "3e538fbe-7672-48cf-de98-f45c83fe40a7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "target_VOCAB = np.load(f'{glove_path}WORDNET_VOCAB_exp_01.npy')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5xcZ3cskYM9V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "SPATIAL_TAGS = np.load(f'{glove_path}WORDNET_SPATIAL_TAGS_exp_01.npy')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9qZ2mE4cYM9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7e53kHoFYM9V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    weights_matrix = torch.from_numpy(weights_matrix)\n",
        "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LZ71W2qsYM9V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: np.ndarray, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e3iYdvPUYM9W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class TransformerEncoderRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, weights_matrix:np.ndarray, \n",
        "                 ntoken: int, out_features:int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.model_type = 'Transformer'\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        \n",
        "        self.weights_matrix = weights_matrix\n",
        "        \n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(self.weights_matrix, True)\n",
        "        \n",
        "        # Multi-head attention mechanism is included in TransformerEncoderLayer\n",
        "        # d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=<function relu>, \n",
        "        # layer_norm_eps=1e-05, batch_first=False, norm_first=False, device=None, dtype=None\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout) # activation\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers, norm=None)\n",
        "        \n",
        "        \n",
        "#         padding_idx (int, optional) – If specified, the entries at padding_idx do not contribute to the gradient;\n",
        "#         therefore, the embedding vector at padding_idx is not updated during training,\n",
        "#         i.e. it remains as a fixed “pad”. For a newly constructed Embedding, the embedding vector at\n",
        "#         padding_idx will default to all zeros, but can be updated to another value to be used as the padding vector.\n",
        "        self.emb = nn.Embedding(ntoken, d_model) \n",
        "        self.out_features = out_features\n",
        "        \n",
        "        # Linear layer: returns the last hidden state of the encoder \n",
        "        self.fc = nn.Linear(d_model, embedding_dim)\n",
        "        \n",
        "        # No! Here I am just redoing fully connected connections\n",
        "        # Linear Layer: affine transformation of last hidden layer into shape (1, embedding_dim)\n",
        "        #self.context_vec = nn.Linear(d_model, embedding_dim)\n",
        "        \n",
        "        #self.decoder = nn.Linear(d_model, ntoken)\n",
        "        \n",
        "        # Now, I need to have a Linear space that takes the whole/subset dataframe as input, extracts its spatial_context_vec,\n",
        "        # based on Glove-word-vector + spatial_point,\n",
        "        # then calculates softmax on this distribution\n",
        "        # choose the argmax\n",
        "        # get its spatial tags\n",
        "        # calculate distance loss between them\n",
        "        # do backprop! \n",
        "        # Nx300 into Nx227733: matmul product of two matrices Nx300 and 300x227733 --> Nx227733\n",
        "        # apply softmax to get the probabilities\n",
        "        # apply argmax to get the maximum indices\n",
        "        # use the indices to get the synset names as well as the mapping to coordinates\n",
        "        # into Nx5: mapping to the coordinates\n",
        "        \n",
        "        self.output = nn.Linear(embedding_dim, 5)\n",
        "        #self.wn_embeddings = nn.Linear(1, target_matrix.shape[0])\n",
        "\n",
        "        self.init_weights()\n",
        "        \n",
        "#         weights_matrix = weights_matrix, \n",
        "#                                     ntoken= # false: 300,\n",
        "#                                     out_features=5,\n",
        "#                                     d_model=300,\n",
        "#                                     d_hid=200,\n",
        "#                                     nlayers=2,\n",
        "#                                     nhead=2,\n",
        "#                                     dropout=0.2\n",
        "        \n",
        "        \n",
        "        # -------------------------------------\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        \"initialize weights using uniform distribution\"\n",
        "        initrange = 0.1\n",
        "        self.emb.weight.data.uniform_(-initrange, initrange)\n",
        "        # self.decoder.bias.data.zero_()\n",
        "        # self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "        \n",
        "        #self.output.bias.data.zero_()\n",
        "        #self.output.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        \n",
        "        #src = self.encoder(src) * math.sqrt(self.d_model)\n",
        "        src = torch.mul(self.emb(src), math.sqrt(self.d_model)) #? 1/sqrt!\n",
        "#         print(\"Embedding\", src.shape)\n",
        "#         print('-' * 80)\n",
        "        \n",
        "        \n",
        "        src = self.pos_encoder(src)\n",
        "#         print(\"Positional Encoding\", src.shape)\n",
        "#         print('-' * 80)\n",
        "        \n",
        "        \n",
        "        encoder_output = self.transformer_encoder(src) #, src_mask)\n",
        "#         print(\"Encoder\", encoder_output.shape)\n",
        "#         # print(encoder_output)\n",
        "#         print('-' * 80)\n",
        "        \n",
        "        \n",
        "        linear_layer = self.fc(encoder_output)\n",
        "#         print(\"Linear Layer\", linear_layer.shape)\n",
        "#         # print(linear_layer)\n",
        "#         print('-' * 80)\n",
        "\n",
        "        # calculate the sum/weighted sum/ ?? on the linear layer to get the context vector of size (1, embd_dim)\n",
        "        context_vec = torch.sum(linear_layer, dim=1)\n",
        "#         print(\"Final Context Vector\", context_vec.shape)\n",
        "#         # print(context_vec)\n",
        "#         print('-' * 80)\n",
        "        \n",
        "        # regression output\n",
        "        coordinates = self.output(context_vec)\n",
        "#         print(\"Coordinates from Context Vector\", coordinates.size())\n",
        "#         # print(coordinates)\n",
        "#         print('-'*80)\n",
        "        return coordinates\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r37R6ZW8YM9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geometric Loss"
      ],
      "metadata": {
        "collapsed": false,
        "id": "sp-hIJf-YM9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def coo2point(coo):\n",
        "    # print(coo)\n",
        "    l0 = coo[0]\n",
        "    alpha = coo[1]\n",
        "    alpha_rad = alpha * math.pi / 180\n",
        "    l_i = coo[2]\n",
        "    beta_i = coo[3]\n",
        "    beta_i_rad = beta_i * math.pi / 180\n",
        "    r = coo[4]\n",
        "    \n",
        "    # np.cos() and np.sin() take angles in radian as params\n",
        "    center_pt = torch.tensor([l0 * math.cos(alpha_rad), l0 * math.sin(alpha_rad)], dtype=torch.float64, requires_grad=True)\n",
        "    sense_pt = center_pt + torch.tensor([l_i * math.cos(alpha_rad + beta_i_rad),\n",
        "                                     l_i * math.sin(alpha_rad + beta_i_rad)], dtype=torch.float64, requires_grad=True)\n",
        "    return sense_pt, center_pt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def distance_loss(pred_pt, original_pt, include_r=False, pt_sphere=False, device=DEVICE):\n",
        "    \"\"\"\n",
        "    Calculates the distance between two sense points, including radii.\n",
        "    :param pred_pt:\n",
        "    :param original_pt:\n",
        "    :param include_r: if set to true, include radius in the distance. \n",
        "                      It gives more freedom/tolerance degrees to the loss function. \n",
        "                      Loss is satisfied once the predicted point is part of original point.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    original_pt = original_pt.to(device)\n",
        "    pred_pt = pred_pt.to(device)\n",
        "    \n",
        "    # original_pt = torch.from_numpy(original_pt)\n",
        "    # print(\"original point\", type(original_pt), original_pt)\n",
        "    \n",
        "    r1 = pred_pt[-1]\n",
        "    r2 = original_pt[-1]\n",
        "\n",
        "    pred_sense, pred_center = coo2point(pred_pt)\n",
        "    orig_sense, orig_center = coo2point(original_pt)\n",
        "\n",
        "    # print(\"original_pt\", original_pt.get_device())\n",
        "    # print(\"pred_pt\", pred_pt.get_device())\n",
        "    #print(\"Equality\", torch.all(original_pt.eq(torch.zeros(original_pt.size(0)).to(device))))\n",
        "    \n",
        "    loss = torch.linalg.norm(torch.sub(pred_sense, orig_sense)) - r2\n",
        "    \n",
        "    # very strong assumption for the words that are not sense-tagged\n",
        "    # If I want more tolerance, I could neglect those tokens from the beginning\n",
        "    if torch.all(torch.eq(original_pt, torch.zeros(original_pt.size(0)).to(device)), dim=0):\n",
        "        return loss\n",
        "    \n",
        "    if pt_sphere:\n",
        "        dist = torch.linalg.norm(torch.sub(pred_sense, orig_sense)) + r2\n",
        "        return dist\n",
        "\n",
        "    \n",
        "    if include_r:\n",
        "        \n",
        "        tolerant_loss = r1 + loss - r2\n",
        "    \n",
        "        if tolerant_loss < 0:\n",
        "            tolerant_loss = 0.0\n",
        "        \n",
        "#         if r1 > r2: #case the predicted radius is bigger than actual one\n",
        "#             tolerant_loss = torch.abs(torch.sub(r1, r2))\n",
        "           \n",
        "        return tolerant_loss\n",
        "    \n",
        "    else:\n",
        "        return loss \n",
        "   \n",
        "\n",
        "\n",
        "def geometric_loss(pred_list, label_list, include_r=False, device=DEVICE):\n",
        "    \n",
        "    # assert that the two lists must be of equal size\n",
        "    pred_size = pred_list.size()[0]\n",
        "    lab_size = label_list.size()[0]\n",
        "    \n",
        "    assert pred_size == lab_size, \"predicted coordinates <{}> and true coordinates <{}> have different sizes\".format(pred_list, label_list)\n",
        "    \n",
        "    sentence_loss = 0.0\n",
        "    \n",
        "    # sum over all the tokens in the sentence\n",
        "    for i in range(pred_size):\n",
        "        sentence_loss += distance_loss(pred_list[i], label_list[i], include_r, device)\n",
        "        \n",
        "    return sentence_loss"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oUoDMuy2YM9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ❌ Sense Inference"
      ],
      "metadata": {
        "collapsed": false,
        "id": "buL4R4UuYM9c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def is_contained(pred, sphere_coo, compare_spheres=False):\n",
        "\n",
        "    pt, word = coo2point(pred)\n",
        "    sphere_sense, sphere_center = coo2point(sphere_coo)\n",
        "\n",
        "    pt_rad = pred[-1]\n",
        "    sphere_rad = sphere_coo[-1] # in angles\n",
        "    \n",
        "    \n",
        "    \n",
        "    if compare_spheres == False:\n",
        "        contained = (pt[0] - sphere_sense[0])**2 + (pt[1] - sphere_sense[1])**2 <= sphere_rad**2\n",
        "    else:\n",
        "        contained = pt_rad + torch.linalg.norm(pt - sphere_sense) - sphere_rad <= 0\n",
        "\n",
        "    if contained:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "\n",
        "@jit(nopython=True)\n",
        "def vicinity_matrix(spatial_params, target_vocab: np.ndarray, spatial_tags: np.ndarray, k=5, device=DEVICE):#, include_sphere=True, include_r=True) -> [str]:\n",
        "    \"\"\"\n",
        "    Projects the predicted spatial parameters into the embedding space.\n",
        "    Returns the synsets in the vicinity of the projected point.\n",
        "    :param spatial_params:\n",
        "    :return: Vicinity matrix, synsets dict\n",
        "    \"\"\"\n",
        "\n",
        "    # send to GPU\n",
        "    spatial_params = spatial_params.to(device)\n",
        "\n",
        "\n",
        "    N = len(spatial_tags)\n",
        "    \n",
        "    #convert spatial_tags to tensor\n",
        "    spatial_tags = torch.from_numpy(spatial_tags).double().to(device)\n",
        "    \n",
        "    synsets = {} # sort from most specific to most general\n",
        "    \n",
        "    indices = {}\n",
        "\n",
        "    sense_pt, center_pt = coo2point(spatial_params)\n",
        "    \n",
        "    # ----------------------------------------------------------------------------------------------------------------\n",
        "    # Prepare distance and containment calculations\n",
        "    # ----------------------------------------------------------------------------------------------------------------\n",
        "    \n",
        "    # distance calculations\n",
        "    dist_spheres = torch.empty(N, device=device) \n",
        "    dist_pt_sphere = torch.empty(N, device=device) \n",
        "    dist_pts = torch.empty(N, device=device)\n",
        "    \n",
        "    for i, tag in enumerate(spatial_tags):\n",
        "        dist_spheres[i] = distance_loss(spatial_params, tag, include_r=True)\n",
        "        dist_pt_sphere[i] = distance_loss(spatial_params, tag, pt_sphere=True)\n",
        "        dist_pts[i] = distance_loss(spatial_params, tag, include_r=False)\n",
        "    \n",
        "    # containment calculations\n",
        "    full_contained = torch.empty(N, device=device) \n",
        "    part_contained = torch.empty(N, device=device)\n",
        "    disconnected = torch.empty(N, device=device) # handles points only\n",
        "    \n",
        "    for j, tag in enumerate(spatial_tags):\n",
        "        full_contained[j] = is_contained(spatial_params, tag, compare_spheres=True)\n",
        "        part_contained[j] = distance_loss(spatial_params, tag, include_r=True, device=device) > 0\n",
        "        disconnected[j] = ~ is_contained(spatial_params, tag, compare_spheres=True) # reverse the True <----> False\n",
        "    \n",
        "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    # Initialize the Vicinity Matrix\n",
        "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    \n",
        "    # row=3, col=3, topk=2, 2 indicates the column of indices and the distances\n",
        "    vicinity_matrix = torch.zeros((3,3, k, 2), device=device)\n",
        "    \n",
        "    ####################################################################################################################\n",
        "    # # Full contained + min dist between sense points\n",
        "    ####################################################################################################################\n",
        "    \n",
        "#     print(\"True elements\")\n",
        "    true_indices1 = (full_contained == True).nonzero(as_tuple=True)[0]\n",
        "#     print(true_indices1)\n",
        "    \n",
        "    if true_indices1.size(0) != 0:\n",
        "        dist1 = torch.index_select(dist_pts, 0, true_indices1)\n",
        "#         print(\"dist1\", dist1)\n",
        "#         print(\"k = \", k)\n",
        "        # sort in ascending order\n",
        "        # select top k \n",
        "        sort_dist1, sort_indices = torch.topk(dist1, k, largest=False)  \n",
        "#         print(\"SORTING\", sort_dist1, sort_indices)\n",
        "        synsets1 = np.take(target_vocab, sort_indices, 0)\n",
        "        synsets[\"A\"] = [synsets1, sort_dist1]\n",
        "        indices[\"A\"] = sort_indices\n",
        "        # index, distance (without synsets because this would result in conflicts for torch.tensor that do not support str)\n",
        "        vicinity_matrix[2][0] = torch.stack((sort_indices, sort_dist1), dim=1)\n",
        "    else:\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    ####################################################################################################################\n",
        "    # # Partially contained + min dist between sense points\n",
        "    ####################################################################################################################\n",
        "    true_indices2 = (part_contained == True).nonzero(as_tuple=True)[0]\n",
        "#     print(\"True Indices 2\", true_indices2)\n",
        "    \n",
        "    if true_indices2.size(0) != 0:\n",
        "        dist1 = torch.index_select(dist_pts, 0, true_indices2)\n",
        "        # sort in ascending order\n",
        "        # select top k \n",
        "        sort_dist2, sort_indices2 = torch.topk(dist1, k, largest=False)     \n",
        "        synsets2 = np.take(target_vocab, sort_indices2, 0)\n",
        "#         print(\"synset 2\", synsets2)\n",
        "        synsets[\"B\"] = [synsets2, sort_dist2]\n",
        "        indices[\"B\"] = sort_indices2\n",
        "        # index, distance (without synsets because this would result in conflicts for torch.tensor that do not support str)\n",
        "        vicinity_matrix[2][1] = torch.stack((sort_indices2, sort_dist2), dim=1)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    ####################################################################################################################\n",
        "    # # Disconnected + min dist between spheres/point2sphere/sense points ---> acts as Nearest neighbor\n",
        "    ####################################################################################################################\n",
        "    # get indices, where disconnected is true\n",
        "    true_indices3 = (disconnected == True).nonzero(as_tuple=True)[0]\n",
        "#     print(\"True Indices 3\", true_indices3)\n",
        "\n",
        "    if true_indices3.size(0) != 0:\n",
        "        # get the distances at those indices\n",
        "        dist_spheres3 = torch.index_select(dist_spheres, 0, true_indices3)\n",
        "        dist_pt_sphere3 = torch.index_select(dist_pt_sphere, 0, true_indices3)\n",
        "        dist_pts3 = torch.index_select(dist_pts, 0, true_indices3)\n",
        "\n",
        "        # sort-select top k minimum distances\n",
        "        sort_dist_spheres3, sort_sph_indices3 = torch.topk(dist_spheres3, k, largest=False)\n",
        "        sort_dist_pt_sphere3, sort_pt_sph_indices3 = torch.topk(dist_pt_sphere3, k, largest=False)\n",
        "        sort_dist_pts3, sort_pts_indices3 = torch.topk(dist_pts3, k, largest=False)\n",
        "\n",
        "        # get their corresponding synsets\n",
        "        synsets30 = np.take(target_vocab, sort_sph_indices3, 0)\n",
        "        #print(\"synset30\", synsets30)\n",
        "        synsets[\"C\"] = [synsets30, sort_dist_spheres3]\n",
        "        indices[\"C\"] = sort_sph_indices3\n",
        "        \n",
        "        synsets31 = np.take(target_vocab, sort_pt_sph_indices3, 0)\n",
        "        synsets[\"D\"] = [synsets31, sort_dist_pt_sphere3]\n",
        "        indices[\"D\"] = sort_pt_sph_indices3\n",
        "        \n",
        "        synsets32 = np.take(target_vocab, sort_pts_indices3, 0)\n",
        "        synsets[\"E\"] = [synsets32, sort_dist_pts3]\n",
        "        indices[\"E\"] = sort_pts_indices3\n",
        "        \n",
        "        # insert them into the vicinity matrix    \n",
        "        vicinity_matrix[0][3] = torch.stack((sort_sph_indices3, sort_dist_spheres3), dim=1)\n",
        "        vicinity_matrix[1][3] = torch.stack((sort_pt_sph_indices3, sort_dist_pt_sphere3), dim=1)\n",
        "        vicinity_matrix[2][3] = torch.stack((sort_pts_indices3, sort_dist_pts3), dim=1)  \n",
        "    \n",
        "\n",
        "\n",
        "#     # get the spheres, where the point/point+radius is contained/overlaping/near\n",
        "\n",
        "#     # 1. check if the predicted point is contained in some sense\n",
        "#     contained = torch.empty(N)\n",
        "    \n",
        "#     for i, tag in enumerate(spatial_tags):\n",
        "#         contained[i] = is_contained(spatial_params, tag, compare_spheres=include_sphere)\n",
        "    \n",
        "#     # 2. For those synsets, which is the nearest synset point\n",
        "#     #use distance() to calculate distance between centers\n",
        "#     distances = torch.empty(N)\n",
        "#     for i, tag in enumerate(spatial_tags):\n",
        "#         distances[i] = distance_loss(spatial_params, tag, include_r=include_r)\n",
        "    \n",
        "#     # sort dist--> indices\n",
        "#     # check if for those distances the containment is true\n",
        "#     # if true: choose the one having min_dist as sense\n",
        "#     # top k senses must be stored in a dict \n",
        "    \n",
        "#     # check if for those distances the containment is false, then, only the radius is falsly predicted (not priority now)\n",
        "#     # if false and min_dist: choose it as potential sense\n",
        "    \n",
        "    \n",
        "\n",
        "#     # 3. If None of the synsets apply to that word sense\n",
        "#     # use sphere_dist to find the nearest sphere (most general synset), and assign it to that synset\n",
        "#     # (this maybe good for rare senses)\n",
        "#     # acts as a second chance\n",
        "#     rare_contained = torch.empty(N)\n",
        "#     rare_distances = torch.empty(N)\n",
        "#     for i, tag in enumerate(spatial_tags):\n",
        "#         rare_contained[i] = is_contained(spatial_params, tag, compare_spheres=False) #only consider sense point\n",
        "#         rare_distances[i] = distance_loss(spatial_params, tag, include_r=False)\n",
        "\n",
        "\n",
        "    return indices, vicinity_matrix, synsets\n",
        "\n",
        "def decode_key(key, mtx):\n",
        "    if key == \"A\":\n",
        "        return mtx[2, 0]\n",
        "    if key == \"B\":\n",
        "        return mtx[2, 1]\n",
        "    if key == \"C\":\n",
        "        return mtx[0, 2]\n",
        "    if key == \"D\":\n",
        "        return mtx[1, 2]\n",
        "    if key == \"E\":\n",
        "        return mtx[2, 2]\n",
        "    \n",
        "@jit(nopython=True)\n",
        "def label_in_vicinity(vicinity_matrix, vicinity_synsets, target_vocab, spatial_tags, true_label):\n",
        "    \n",
        "    checked_synsets = []\n",
        "    contained = []\n",
        "    checks = 0\n",
        "    predicted = []\n",
        "    distances = []\n",
        "    \n",
        "    in_vicinity = False\n",
        "    associated_syn = []\n",
        "    \n",
        "    # true label is either one of the possibilities [word, synset] or a randomly chosen one\n",
        "    \n",
        "    # induce subset of word-synset name \n",
        "    \n",
        "    #spatial_tags = torch.from_numpy(spatial_tags)\n",
        "    #idx_label = (spatial_tags == true_label).nonzero(as_tuple=True)[0]\n",
        "    # transform to numpy to \n",
        "    true_label = true_label.cpu().numpy()\n",
        "    true_label = np.array(true_label, dtype=np.float64)\n",
        "    # keep spatial tag an np.ndarray\n",
        "    rounded_l = np.round(true_label, decimals=2).cpu()\n",
        "    \n",
        "    if np.all(rounded_l == np.zeros(5)): #true_label): #torch.all(torch.eq(rounded_l, true_label)):\n",
        "        in_vicinity = False #True\n",
        "        associated_syn.append('no-synset')\n",
        "        return in_vicinity, associated_syn\n",
        "    \n",
        "    try:\n",
        "        # detecting the true label from the spatial_tags\n",
        "        idx = [[np.array_equal(rounded_l, tag) for tag in spatial_tags].index(True)]\n",
        "#         print(\"Found {} matching word-synset tags.\".format(len(idx)))\n",
        "        word_synset = target_vocab[idx] #list of list \n",
        "#         print(\"Matching word-synset\", word_synset)\n",
        "        # check if word_synset is within the vicinity matrix\n",
        "        if len(word_synset) != 0:\n",
        "            for e in word_synset:\n",
        "                for key, val in vicinity_synsets.items():\n",
        "#                     print(\"Searching in vicinity ... \")\n",
        "\n",
        "#                     print(\"Checking if true label is in vicinity ...\")\n",
        "                    checked_synsets.append(e)\n",
        "                    is_there = e[1] in val[:, 1]\n",
        "                    checks += 1\n",
        "                    contained.append(is_there)\n",
        "                    \n",
        "#                     print(\"1\")\n",
        "#                     print(checked_synsets)\n",
        "#                     print(checks)\n",
        "#                     print(contained)\n",
        "                    \n",
        "                    if is_there:\n",
        "#                         print(\"The main true label <{}> is in the vacinity of the predicted tag.\".format(e))\n",
        "                        idx_e = np.where(val[:, 1] == e[1])\n",
        "                        predicted.append(val[idx_e])\n",
        "#                         print(\"Predicted 1: \", predicted)\n",
        "                        distances.append(decode_key(key, vicinity_matrix)[idx_e][1])\n",
        "#                         print(\"Distances 1: \", distances)\n",
        "                    else:\n",
        "#                         print(\"The main true label is not in vicinity ... \")\n",
        "                        distances.append('no-distance')\n",
        "#                         print(\"Searching if alternative true label synsets are in vicinity ... \")\n",
        "                    # induce all the word-synset tuples that have same synset as true label.\n",
        "                    # This double check is necessary since I choose the spatial tags in the training data randomly sometimes.\n",
        "                    # get indices of all word-synsets sharing same synset (not same word)\n",
        "                    ix = np.where(target_vocab == [_, e[1]])[0] # add [0] to indicate only the row index, not the column\n",
        "#                     print(\"Indices \", ix)\n",
        "                    if len(ix) != 0:\n",
        "                        pos_syn = target_vocab[ix]\n",
        "                        \n",
        "#                         print(\"Possible synsets: \", pos_syn)\n",
        "#                         print(target_vocab[:10])\n",
        "                        for t in pos_syn:\n",
        "                            checks += 1\n",
        "                            checked_synsets.append(t)\n",
        "                            is_near = t[1] in val[:, -1]\n",
        "                            contained.append(is_near)\n",
        "#                             print(\"2\")\n",
        "#                             print(checked_synsets)\n",
        "#                             print(checks)\n",
        "#                             print(contained)\n",
        "                            if is_near == True:                                    \n",
        "#                                 print(\"... The word-synset <{}> is in the vicinity of the predicted tag.\".format(t))\n",
        "                                idx_t = np.where(val[:, -1] == t[1])\n",
        "                                predicted.append(val[idx_t])\n",
        "#                                 print(\"Predicted 2: \", predicted)\n",
        "                                distances.append(decode_key(key, vicinity_matrix)[idx_t][1])\n",
        "#                                 print(\"Distances 2: \", distances)\n",
        "                            else:\n",
        "                                distances.append('no-distance')\n",
        "                    else: \n",
        "                        print(\"... There are no other possibilites for word-synset <{}>\".format(e))\n",
        "                            \n",
        "        else:\n",
        "            print(\"Cannot find the suitable synset of this spatial tag!\")\n",
        "\n",
        "        \n",
        "    except ValueError as ve:\n",
        "        print(ve)\n",
        "#         print(\"Found no index for the true label. Something went wrong ...\")\n",
        "#         print(\"Comparing <true label = {}> with <rounded label = {}>\".format(true_label, rounded_l))\n",
        "    \n",
        "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    # Statistics\n",
        "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    \n",
        "#     print(\"~\" * 80)\n",
        "#     print(\"Statistics\")\n",
        "#     print(\"~\" * 80)\n",
        "    \n",
        "#     print(\"Predicted Spatial Tag = \", spatial_params)\n",
        "#     print(\"Checked Spatial Tag(s) ; contained? ; Predicted ; distances = ({}):\".format(len(checked_synsets)))\n",
        "    for s, c, p, d in zip(checked_synsets, contained, predicted, distances):\n",
        "        print(s, \";\", c, \";\", \"\\n\", p, \";\", d)\n",
        "        print(\"-\"*100)\n",
        "        \n",
        "#     print(\"True Spatial Tag(s) is in vicinity of predicted tag: \", contained)\n",
        "    contained_idx = np.where(np.array(contained) == True)\n",
        "    \n",
        "#     print(\"contained_idx\", contained_idx)\n",
        "#     print(\"checked_idx\", np.array(checked_synsets)[contained_idx])\n",
        "#     print(\"slice\", np.array(checked_synsets)[:, 1])\n",
        "#     print(\"check_slice\", np.array(checked_synsets)[:, 1][contained_idx])\n",
        "\n",
        "    if len(contained_idx[0]) > 0:\n",
        "#         print()\n",
        "#         print(contained_idx)\n",
        "        only_syn = set(np.array(checked_synsets)[contained_idx])#[:, 1])\n",
        "        associated_syn.append(only_syn)\n",
        "#         print(\"True Sense Tag(s) = ({}) --> \".format(len(only_syn)), only_syn)\n",
        "#         print(\"Prediction is correct!\")\n",
        "        in_vicinity = True\n",
        "#         print(\"Distance(predicted_sense, nearest_true_sense) = ({}): \".format(len(np.array(predicted)[contained_idx])))\n",
        "#         for p, d in zip(np.array(predicted), distances):\n",
        "#               print(p, d)\n",
        "              \n",
        "    else:\n",
        "#         print(\"Prediction is false ..\")\n",
        "#         print(\"All synsets in the vicinity of the predicted tag are not true senses ..\")\n",
        "#         print(\"Please check manually if the synsets in the vicinity are generalizations of the true labels.\")\n",
        "        in_vicinity = False\n",
        "        associated_syn.append(\"no-synset\")\n",
        "    \n",
        "    \n",
        "    return in_vicinity, associated_syn\n",
        "    "
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HszRl34EYM9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sense Inference Unification"
      ],
      "metadata": {
        "id": "0vR0knpCt5zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_contained(pred, sphere_coo, compare_spheres=False):\n",
        "\n",
        "    pt, word = coo2point(pred)\n",
        "    sphere_sense, sphere_center = coo2point(sphere_coo)\n",
        "\n",
        "    pt_rad = pred[-1]\n",
        "    sphere_rad = sphere_coo[-1] # in angles\n",
        "    \n",
        "    \n",
        "    \n",
        "    if compare_spheres == False:\n",
        "        contained = (pt[0] - sphere_sense[0])**2 + (pt[1] - sphere_sense[1])**2 <= sphere_rad**2\n",
        "    else:\n",
        "        contained = pt_rad + torch.linalg.norm(pt - sphere_sense) - sphere_rad <= 0\n",
        "\n",
        "    if contained:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "\n",
        "def vicinity_matrix(spatial_params, target_vocab: np.ndarray, spatial_tags: np.ndarray, k=5, device=DEVICE):#, include_sphere=True, include_r=True) -> [str]:\n",
        "    \"\"\"\n",
        "    Projects the predicted spatial parameters into the embedding space.\n",
        "    Returns the synsets in the vicinity of the projected point.\n",
        "    :param spatial_params:\n",
        "    :return: Vicinity matrix, synsets dict\n",
        "    \"\"\"\n",
        "\n",
        "    # send to GPU\n",
        "    spatial_params = spatial_params.to(device)\n",
        "\n",
        "\n",
        "    N = len(spatial_tags)\n",
        "    \n",
        "    #convert spatial_tags to tensor\n",
        "    spatial_tags = torch.from_numpy(spatial_tags).double().to(device)\n",
        "    \n",
        "    synsets = {} # sort from most specific to most general\n",
        "    \n",
        "    indices = {}\n",
        "\n",
        "    sense_pt, center_pt = coo2point(spatial_params)\n",
        "    \n",
        "    # ----------------------------------------------------------------------------------------------------------------\n",
        "    # Prepare distance and containment calculations\n",
        "    # ----------------------------------------------------------------------------------------------------------------\n",
        "    \n",
        "    # distance calculations\n",
        "    dist_spheres = torch.empty(N, device=device) \n",
        "    dist_pt_sphere = torch.empty(N, device=device) \n",
        "    dist_pts = torch.empty(N, device=device)\n",
        "    \n",
        "    for i, tag in enumerate(spatial_tags):\n",
        "        dist_spheres[i] = distance_loss(spatial_params, tag, include_r=True)\n",
        "        dist_pt_sphere[i] = distance_loss(spatial_params, tag, pt_sphere=True)\n",
        "        dist_pts[i] = distance_loss(spatial_params, tag, include_r=False)\n",
        "    \n",
        "    # containment calculations\n",
        "    full_contained = torch.empty(N, device=device) \n",
        "    part_contained = torch.empty(N, device=device)\n",
        "    disconnected = torch.empty(N, device=device) # handles points only\n",
        "    \n",
        "    for j, tag in enumerate(spatial_tags):\n",
        "        full_contained[j] = is_contained(spatial_params, tag, compare_spheres=True)\n",
        "        part_contained[j] = distance_loss(spatial_params, tag, include_r=True, device=device) > 0\n",
        "        disconnected[j] = ~ is_contained(spatial_params, tag, compare_spheres=True) # reverse the True <----> False\n",
        "    \n",
        "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    # Initialize the Vicinity Matrix\n",
        "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    \n",
        "    # row=3, col=3, topk=2, 2 indicates the column of indices and the distances\n",
        "    vicinity_matrix = torch.zeros((3,3, k, 2), device=device)\n",
        "    \n",
        "    ####################################################################################################################\n",
        "    # # Full contained + min dist between sense points\n",
        "    ####################################################################################################################\n",
        "    \n",
        "#     print(\"True elements\")\n",
        "    true_indices1 = (full_contained == True).nonzero(as_tuple=True)[0]\n",
        "#     print(true_indices1)\n",
        "    \n",
        "    if true_indices1.size(0) != 0:\n",
        "        dist1 = torch.index_select(dist_pts, 0, true_indices1)\n",
        "#         print(\"dist1\", dist1)\n",
        "#         print(\"k = \", k)\n",
        "        # sort in ascending order\n",
        "        # select top k \n",
        "        sort_dist1, sort_indices = torch.topk(dist1, k, largest=False)  \n",
        "#         print(\"SORTING\", sort_dist1, sort_indices)\n",
        "        # numby error: remove numpy\n",
        "        #synsets1 = np.take(target_vocab, sort_indices, 0)\n",
        "        #synsets[\"A\"] = [synsets1, sort_dist1]\n",
        "        synsets[\"A\"] = sort_dist1\n",
        "        indices[\"A\"] = sort_indices\n",
        "        # index, distance (without synsets because this would result in conflicts for torch.tensor that do not support str)\n",
        "        vicinity_matrix[2][0] = torch.stack((sort_indices, sort_dist1), dim=1)\n",
        "    else:\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    ####################################################################################################################\n",
        "    # # Partially contained + min dist between sense points\n",
        "    ####################################################################################################################\n",
        "    true_indices2 = (part_contained == True).nonzero(as_tuple=True)[0]\n",
        "#     print(\"True Indices 2\", true_indices2)\n",
        "    \n",
        "    if true_indices2.size(0) != 0:\n",
        "        dist1 = torch.index_select(dist_pts, 0, true_indices2)\n",
        "        # sort in ascending order\n",
        "        # select top k \n",
        "        sort_dist2, sort_indices2 = torch.topk(dist1, k, largest=False) \n",
        "        # numby error: remove numpy    \n",
        "        # synsets2 = np.take(target_vocab, sort_indices2, 0)\n",
        "#         print(\"synset 2\", synsets2)\n",
        "        #synsets[\"B\"] = [synsets2, sort_dist2]\n",
        "        synsets[\"B\"] = sort_dist2\n",
        "        indices[\"B\"] = sort_indices2\n",
        "        # index, distance (without synsets because this would result in conflicts for torch.tensor that do not support str)\n",
        "        vicinity_matrix[2][1] = torch.stack((sort_indices2, sort_dist2), dim=1)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    ####################################################################################################################\n",
        "    # # Disconnected + min dist between spheres/point2sphere/sense points ---> acts as Nearest neighbor\n",
        "    ####################################################################################################################\n",
        "    # get indices, where disconnected is true\n",
        "    true_indices3 = (disconnected == True).nonzero(as_tuple=True)[0]\n",
        "#     print(\"True Indices 3\", true_indices3)\n",
        "\n",
        "    if true_indices3.size(0) != 0:\n",
        "        # get the distances at those indices\n",
        "        dist_spheres3 = torch.index_select(dist_spheres, 0, true_indices3)\n",
        "        dist_pt_sphere3 = torch.index_select(dist_pt_sphere, 0, true_indices3)\n",
        "        dist_pts3 = torch.index_select(dist_pts, 0, true_indices3)\n",
        "\n",
        "        # sort-select top k minimum distances\n",
        "        sort_dist_spheres3, sort_sph_indices3 = torch.topk(dist_spheres3, k, largest=False)\n",
        "        sort_dist_pt_sphere3, sort_pt_sph_indices3 = torch.topk(dist_pt_sphere3, k, largest=False)\n",
        "        sort_dist_pts3, sort_pts_indices3 = torch.topk(dist_pts3, k, largest=False)\n",
        "\n",
        "        # get their corresponding synsets\n",
        "        # remove numpy because of numby error\n",
        "        #synsets30 = np.take(target_vocab, sort_sph_indices3, 0)\n",
        "        #print(\"synset30\", synsets30)\n",
        "        #synsets[\"C\"] = [synsets30, sort_dist_spheres3]\n",
        "        synsets[\"C\"] = sort_dist_spheres3\n",
        "        indices[\"C\"] = sort_sph_indices3\n",
        "        \n",
        "        #synsets31 = np.take(target_vocab, sort_pt_sph_indices3, 0)\n",
        "        # synsets[\"D\"] = [synsets31, sort_dist_pt_sphere3]\n",
        "        synsets[\"D\"] = sort_dist_pt_sphere3\n",
        "        indices[\"D\"] = sort_pt_sph_indices3\n",
        "        \n",
        "        #synsets32 = np.take(target_vocab, sort_pts_indices3, 0)\n",
        "        # synsets[\"E\"] = [synsets32, sort_dist_pts3]\n",
        "        synsets[\"E\"] = sort_dist_pts3\n",
        "        indices[\"E\"] = sort_pts_indices3\n",
        "        \n",
        "        # insert them into the vicinity matrix    \n",
        "        vicinity_matrix[0][3] = torch.stack((sort_sph_indices3, sort_dist_spheres3), dim=1)\n",
        "        vicinity_matrix[1][3] = torch.stack((sort_pt_sph_indices3, sort_dist_pt_sphere3), dim=1)\n",
        "        vicinity_matrix[2][3] = torch.stack((sort_pts_indices3, sort_dist_pts3), dim=1)  \n",
        "    \n",
        "\n",
        "\n",
        "#     # get the spheres, where the point/point+radius is contained/overlaping/near\n",
        "\n",
        "#     # 1. check if the predicted point is contained in some sense\n",
        "#     contained = torch.empty(N)\n",
        "    \n",
        "#     for i, tag in enumerate(spatial_tags):\n",
        "#         contained[i] = is_contained(spatial_params, tag, compare_spheres=include_sphere)\n",
        "    \n",
        "#     # 2. For those synsets, which is the nearest synset point\n",
        "#     #use distance() to calculate distance between centers\n",
        "#     distances = torch.empty(N)\n",
        "#     for i, tag in enumerate(spatial_tags):\n",
        "#         distances[i] = distance_loss(spatial_params, tag, include_r=include_r)\n",
        "    \n",
        "#     # sort dist--> indices\n",
        "#     # check if for those distances the containment is true\n",
        "#     # if true: choose the one having min_dist as sense\n",
        "#     # top k senses must be stored in a dict \n",
        "    \n",
        "#     # check if for those distances the containment is false, then, only the radius is falsly predicted (not priority now)\n",
        "#     # if false and min_dist: choose it as potential sense\n",
        "    \n",
        "    \n",
        "\n",
        "#     # 3. If None of the synsets apply to that word sense\n",
        "#     # use sphere_dist to find the nearest sphere (most general synset), and assign it to that synset\n",
        "#     # (this maybe good for rare senses)\n",
        "#     # acts as a second chance\n",
        "#     rare_contained = torch.empty(N)\n",
        "#     rare_distances = torch.empty(N)\n",
        "#     for i, tag in enumerate(spatial_tags):\n",
        "#         rare_contained[i] = is_contained(spatial_params, tag, compare_spheres=False) #only consider sense point\n",
        "#         rare_distances[i] = distance_loss(spatial_params, tag, include_r=False)\n",
        "\n",
        "\n",
        "    return indices, vicinity_matrix, synsets\n",
        "\n",
        "@jit(nopython=True)\n",
        "def decode_key(key, mtx):\n",
        "    if key == \"A\":\n",
        "        return mtx[2, 0]\n",
        "    if key == \"B\":\n",
        "        return mtx[2, 1]\n",
        "    if key == \"C\":\n",
        "        return mtx[0, 2]\n",
        "    if key == \"D\":\n",
        "        return mtx[1, 2]\n",
        "    if key == \"E\":\n",
        "        return mtx[2, 2]\n",
        "\n",
        "\n",
        "#@jit(nopython=True)\n",
        "def label_in_vicinity(vicinity_matrix, \n",
        "                      vicinity_indices,\n",
        "                      #vicinity_synsets, \n",
        "                      target_vocab, spatial_tags, true_label_idx):\n",
        "    t0 = time.time()\n",
        "    \n",
        "    # vicinity_matrix = vicinity_matrix.cpu().detach().numpy()\n",
        "    # print(\"vicinity matrix within label in vicinity!\", vicinity_matrix) #vicinity_matrix.get_device())\n",
        "\n",
        "    checked_synsets = []\n",
        "    contained = []\n",
        "    checks = 0\n",
        "    predicted = []\n",
        "    distances = []\n",
        "    \n",
        "    in_vicinity = False\n",
        "    associated_syn = []\n",
        "\n",
        "    true_label = spatial_tags[true_label_idx]\n",
        "\n",
        "    \n",
        "    # # true label is either one of the possibilities [word, synset] or a randomly chosen one\n",
        "    # # induce subset of word-synset name \n",
        "    # rounded_l = np.round(true_label, decimals=2)\n",
        "    \n",
        "    # if np.all(rounded_l == np.zeros(5)): #true_label): #torch.all(torch.eq(rounded_l, true_label)):\n",
        "    #     in_vicinity = False #True\n",
        "    #     associated_syn.append('no-synset')\n",
        "    #     #return in_vicinity, associated_syn\n",
        "        \n",
        "# try:\n",
        "    # # detecting the true label from the spatial_tags\n",
        "    # idx = [[np.array_equal(rounded_l, tag) for tag in spatial_tags].index(True)]\n",
        "    # print(\"Found {} matching word-synset tags.\".format(len(idx)))\n",
        "    idx = true_label_idx\n",
        "    word_synset = target_vocab[idx] #list of list \n",
        "    #print(\"Matching word-synset\", word_synset)\n",
        "    # check if word_synset is within the vicinity matrix\n",
        "    if len(word_synset) != 0:\n",
        "        for e in word_synset:\n",
        "            for key, val in vicinity_indices.items(): #vicinity_indices {\"B\": tensor([84, 26, 79, 63, 37])}\n",
        "                # print(\"Searching in vicinity ... \")\n",
        "                #val = val.cpu().numpy()\n",
        "\n",
        "                print(\"Checking if true label is in vicinity ...\")\n",
        "                checked_synsets.append(e)\n",
        "                idx2sense = target_vocab[val]\n",
        "                print(\"idx2sense 1: \", idx2sense)\n",
        "                #is_there = e[1] in val[:, 1]\n",
        "                is_there = e[1] in idx2sense[:, 1]\n",
        "                checks += 1\n",
        "                contained.append(is_there)\n",
        "                \n",
        "                print(\"1\")\n",
        "                # print(checked_synsets)\n",
        "                print(checks)\n",
        "                # print(contained)\n",
        "                \n",
        "                if is_there:\n",
        "                    print(\"The main true label <{}> is in the vacinity of the predicted tag.\".format(e))\n",
        "                    # idx_e = np.where(val[:, 1] == e[1])\n",
        "                    idx_e = np.where(idx2sense[:, 1] == e[1])\n",
        "                    predicted.append(idx2sense[idx_e])\n",
        "#                         print(\"Predicted 1: \", predicted)\n",
        "                    distances.append(decode_key(key, vicinity_matrix)[idx_e][1])\n",
        "#                         print(\"Distances 1: \", distances)\n",
        "                else:\n",
        "#                         print(\"The main true label is not in vicinity ... \")\n",
        "                    distances.append('no-distance')\n",
        "#                         print(\"Searching if alternative true label synsets are in vicinity ... \")\n",
        "                # induce all the word-synset tuples that have same synset as true label.\n",
        "                # This double check is necessary since I choose the spatial tags in the training data randomly sometimes.\n",
        "                # get indices of all word-synsets sharing same synset (not same word)\n",
        "                ix = np.where(target_vocab == [_, e[1]])[0] # add [0] to indicate only the row index, not the column\n",
        "#                     print(\"Indices \", ix)\n",
        "                if len(ix) != 0:\n",
        "                    pos_syn = target_vocab[ix]\n",
        "                    \n",
        "#                         print(\"Possible synsets: \", pos_syn)\n",
        "#                         print(target_vocab[:10])\n",
        "                    for t in pos_syn:\n",
        "                        checks += 1\n",
        "                        checked_synsets.append(t)\n",
        "                        is_near = t[1] in idx2sense[:, -1]\n",
        "                        contained.append(is_near)\n",
        "                        print(\"2\")\n",
        "#                             print(checked_synsets)\n",
        "                        print(checks)\n",
        "#                             print(contained)\n",
        "                        if is_near == True:                                    \n",
        "#                                 print(\"... The word-synset <{}> is in the vicinity of the predicted tag.\".format(t))\n",
        "                            #idx_t = np.where(val[:, -1] == t[1])\n",
        "                            idx_t = np.where(idx2sense[:, -1] == t[1])\n",
        "                            predicted.append(idx2sense[idx_t])\n",
        "#                                 print(\"Predicted 2: \", predicted)\n",
        "                            distances.append(decode_key(key, vicinity_matrix)[idx_t][1])\n",
        "                            print(\"Distances 2: \", distances)\n",
        "                        else:\n",
        "                            distances.append('no-distance')\n",
        "                else: \n",
        "                    print(\"... There are no other possibilites for word-synset <{}>\".format(e))\n",
        "                        \n",
        "    else:\n",
        "        print(\"Cannot find the suitable synset of this spatial tag!\")\n",
        "\n",
        "    # except Exception:#ValueError as ve:\n",
        "    # #     print(ve)\n",
        "    #      print(\"Found no index for the true label. Something went wrong ...\")\n",
        "         \n",
        "#         print(\"Comparing <true label = {}> with <rounded label = {}>\".format(true_label, rounded_l))\n",
        "    \n",
        "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    # Statistics\n",
        "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    \n",
        "#     print(\"~\" * 80)\n",
        "#     print(\"Statistics\")\n",
        "#     print(\"~\" * 80)\n",
        "    \n",
        "#     print(\"Predicted Spatial Tag = \", spatial_params)\n",
        "#     print(\"Checked Spatial Tag(s) ; contained? ; Predicted ; distances = ({}):\".format(len(checked_synsets)))\n",
        "    for s, c, p, d in zip(checked_synsets, contained, predicted, distances):\n",
        "        print(s, \";\", c, \";\", \"\\n\", p, \";\", d)\n",
        "        print(\"-\"*100)\n",
        "        \n",
        "#     print(\"True Spatial Tag(s) is in vicinity of predicted tag: \", contained)\n",
        "    contained_idx = np.where(np.array(contained) == True)\n",
        "    \n",
        "#     print(\"contained_idx\", contained_idx)\n",
        "#     print(\"checked_idx\", np.array(checked_synsets)[contained_idx])\n",
        "#     print(\"slice\", np.array(checked_synsets)[:, 1])\n",
        "#     print(\"check_slice\", np.array(checked_synsets)[:, 1][contained_idx])\n",
        "\n",
        "    if len(contained_idx[0]) > 0:\n",
        "#         print()\n",
        "#         print(contained_idx)\n",
        "        only_syn = set(np.array(checked_synsets)[contained_idx])#[:, 1])\n",
        "        associated_syn.append(only_syn)\n",
        "#         print(\"True Sense Tag(s) = ({}) --> \".format(len(only_syn)), only_syn)\n",
        "#         print(\"Prediction is correct!\")\n",
        "        in_vicinity = True\n",
        "#         print(\"Distance(predicted_sense, nearest_true_sense) = ({}): \".format(len(np.array(predicted)[contained_idx])))\n",
        "#         for p, d in zip(np.array(predicted), distances):\n",
        "#               print(p, d)\n",
        "              \n",
        "    else:\n",
        "#         print(\"Prediction is false ..\")\n",
        "#         print(\"All synsets in the vicinity of the predicted tag are not true senses ..\")\n",
        "#         print(\"Please check manually if the synsets in the vicinity are generalizations of the true labels.\")\n",
        "        in_vicinity = False\n",
        "        associated_syn.append(\"no-synset\")\n",
        "\n",
        "    t1 = time.time()\n",
        "\n",
        "    print(\"It took {} to run the in_vicinity check\".format(t1-t0))\n",
        "    \n",
        "    \n",
        "    return in_vicinity #, associated_syn\n",
        "    "
      ],
      "metadata": {
        "id": "4sK-iK6lt9XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    'Counts the parameters of the model to allow comparision between different models.'\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KDJe7O3mYM9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training / Validation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "aAF8zYXFYM9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# I need to split all training data beforehand\n",
        "\n",
        "class RegTagger:\n",
        "    \n",
        "    def __init__(self, use_cuda, device):\n",
        "        super().__init__()\n",
        "        self.use_cuda = use_cuda\n",
        "        self.device = device\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "  \n",
        "    def train(self, batch_size: int, num_workers: int, max_epochs: int, \n",
        "              splittings: dict, path2data: str, data: list, embed_size: int,\n",
        "              target_vocab: list, spatial_tags: list,\n",
        "              k=5,\n",
        "              d_model=300, d_hid=200, nlayers=2, nhead=2, dropout=0.2,\n",
        "              lr=5.0, gamma=0.95,\n",
        "              shuffle=True):\n",
        "      \n",
        "        if num_workers > 0:\n",
        "          pin_memory = True\n",
        "        else:\n",
        "          pin_memory = False\n",
        "        \n",
        "        # create batches\n",
        "        \n",
        "        # parameters\n",
        "        params = {'batch_size': batch_size, #64,\n",
        "                  'shuffle': shuffle,\n",
        "                  'collate_fn': lambda x: x,\n",
        "                  'num_workers': num_workers, #6} #set 0 if training on Windows machine\n",
        "                  'pin_memory': pin_memory}\n",
        "\n",
        "        # Training and validation data generators\n",
        "        training_set = Dataset(splittings['train'], path2data)\n",
        "        training_generator = DataLoader(training_set, **params)\n",
        "\n",
        "        validation_set = Dataset(splittings['validate'], path2data)\n",
        "        validation_generator = DataLoader(validation_set, **params)\n",
        "\n",
        "        # -------------------------------------------------\n",
        "    \n",
        "        # history to store the losses\n",
        "        history = defaultdict(list)\n",
        "\n",
        "        VOCAB, weights_matrix = load_vocab(data, embed_size=embed_size)\n",
        "        #weights_matrix = torch.from_numpy(weights_matrix).double().to(self.device)\n",
        "        #print(\"VOCAB\", VOCAB.device())\n",
        "        #print(\"weights_matrix\", weights_matrix.get_device())\n",
        "\n",
        "        # target_VOCAB\n",
        "        # SPATIAL_TAGS\n",
        "\n",
        "    \n",
        "        #######################################################################################################################\n",
        "        #        Count sentences and number of words in training and validation datasets to normalize the loss\n",
        "        #######################################################################################################################\n",
        "        nb_words_training = 0\n",
        "        nb_train_sentences = 0\n",
        "        nb_words_validation = 0\n",
        "\n",
        "        for batch in training_generator:\n",
        "            for sentence, label, syn, idx in batch:\n",
        "                nb_train_sentences += 1\n",
        "                nb_words_training += len(sentence)\n",
        "\n",
        "        for batch in validation_generator:\n",
        "            for sentence, label, syn, idx in batch:\n",
        "                nb_words_validation += len(sentence)\n",
        "\n",
        "        print(\"Count results:\")\n",
        "        print(\"nb_words_training = {}\".format(nb_words_training))\n",
        "        print(\"nb_train_sentences = {}\".format(nb_train_sentences))\n",
        "        print(\"nb_words_validation = {}\".format(nb_words_validation))\n",
        "\n",
        "\n",
        "#         print(params[\"batch_size\"])\n",
        "        n_batches = np.ceil(nb_train_sentences / batch_size)\n",
        "        # n_batches.to(self.device)\n",
        "        # print(\"ceiling\", n_batches.get_device())\n",
        "\n",
        "        mean_words = nb_words_training / n_batches\n",
        "        mean_words = torch.from_numpy(np.array(mean_words).astype('float')).double().to(self.device)\n",
        "        # print(\"mean_words\", mean_words.get_device())\n",
        "\n",
        "\n",
        "\n",
        "        self.model = TransformerEncoderRegressor(weights_matrix = weights_matrix, \n",
        "                                            ntoken= len(VOCAB), #300,\n",
        "                                            out_features=5,\n",
        "                                            d_model=d_model,\n",
        "                                            d_hid=d_hid,\n",
        "                                            nlayers=nlayers,\n",
        "                                            nhead=nhead,\n",
        "                                            dropout=dropout)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # ---------------------------------------------------------------------\n",
        "        #                       Optimizer\n",
        "        # ---------------------------------------------------------------------\n",
        "        # criterion = nn.CrossEntropyLoss()\n",
        "        criterion = nn.MSELoss()\n",
        "#             lr = 5.0  # learning rate\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=gamma)\n",
        "        # -------\n",
        "\n",
        "\n",
        "        # Loop over epochs\n",
        "        for epoch in range(max_epochs):\n",
        "            # print(\"epoch = \", epoch)\n",
        "\n",
        "            t0 = time.time()\n",
        "\n",
        "            loss_sum = 0\n",
        "\n",
        "            self.model.train()\n",
        "\n",
        "            # for transformer\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "            print(\"Training ...\")\n",
        "            # Training\n",
        "            for batch in training_generator:\n",
        "                # print(\"New Batch for Training\")\n",
        "                # print(\"#\" * 100)\n",
        "\n",
        "                for local_batch, local_labels, local_synsets, local_idx in batch:\n",
        "\n",
        "                    # Transform list(<string>) to Tensor(<Tensor>)\n",
        "                    print(\"Input (training)\")\n",
        "                    print(local_batch)\n",
        "                    input_words = local_batch\n",
        "                    local_batch = numericalize(local_batch, VOCAB)\n",
        "#                     print(type(local_batch), local_batch)\n",
        "\n",
        "                    extract_labels = spatial_tags[local_idx]\n",
        "                    local_labels = [torch.tensor(lab) for lab in extract_labels]\n",
        "\n",
        "                    # print(local_idx, local_labels)\n",
        "                    # Transform List(<Tensor>) to Tensor(<Tensor>)\n",
        "                    # I have labels of same length --> this should be no problem for Tensor\n",
        "                    local_labels = torch.stack(local_labels)\n",
        "                    print(\"Labels:\")\n",
        "                    print(local_synsets)\n",
        "                    #print(type(local_labels), len(local_labels), type(local_labels[0]))\n",
        "                    #print(local_labels)\n",
        "\n",
        "                    # Transfer to GPU\n",
        "                    local_batch, local_labels = local_batch.to(self.device), local_labels.to(self.device)\n",
        "\n",
        "                    # Model computations\n",
        "                    # out outputs the indices of wordnet database\n",
        "                    out = self.model(local_batch)\n",
        "                    print(\"Model's Output\")\n",
        "                    print(type(out), out.shape, out)\n",
        "                    # print(out)\n",
        "                    # predicted synsets\n",
        "#                     print(\"Current Predictions based on vacinity of prediction\")\n",
        "#                     print(\"*\" * 100)\n",
        "#                     print(\"*\" * 100)\n",
        "\n",
        "\n",
        "                    # ntokens = len(VOCAB)#300\n",
        "                    loss = geometric_loss(out, local_labels, device=self.device) / mean_words\n",
        "                    # criterion(out.view(-1), local_labels.view(-1))\n",
        "                    print(\"Gemetric Loss = geometric_loss(out, local_labels, device=self.device) / mean_words\")\n",
        "#                     print(type(loss), loss.size())\n",
        "                    print(loss)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    # I added this\n",
        "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
        "                    # ---\n",
        "                    optimizer.step()\n",
        "                    loss_sum += loss.item()\n",
        "                    print(\"Loss Sum\", loss_sum)\n",
        "\n",
        "\n",
        "                    train_loss = loss_sum / len(local_batch)\n",
        "                    history['train_loss'].append(train_loss)\n",
        "#                     print(history)\n",
        "#                     print(len(history['train_loss']))\n",
        "\n",
        "\n",
        "            # Evaluate on the validation set.\n",
        "            # evaluate every 1 step:\n",
        "\n",
        "            print(\"Validation ...\")\n",
        "            vloss_sum = 0\n",
        "            if epoch % 1 == 0:\n",
        "\n",
        "                correct_sense = 0\n",
        "                sense_accuracy = 0\n",
        "\n",
        "                # set model to eval mode to ignore updating the weights of the model\n",
        "                self.model.eval()\n",
        "\n",
        "                # do not calculate gradients while evaluating\n",
        "                with torch.set_grad_enabled(False):\n",
        "\n",
        "                    for batch in validation_generator:\n",
        "                        # print(\"New Batch for Validation\")\n",
        "                        # print(\"#\" * 100)\n",
        "\n",
        "                        for local_batch, local_labels, local_synsets, local_idx in batch:\n",
        "\n",
        "                            # Transform list(<string>) to Tensor(<Tensor>)\n",
        "                            # print(\"Input Sentence\")\n",
        "                            # print(local_batch)\n",
        "                            input_words = local_batch\n",
        "                            local_batch = numericalize(local_batch, VOCAB)\n",
        "        #                     print(type(local_batch), local_batch)\n",
        "\n",
        "                            extract_labels = spatial_tags[local_idx]\n",
        "                            local_labels = [torch.tensor(lab) for lab in extract_labels]\n",
        "\n",
        "\n",
        "                            # Transform List(<Tensor>) to Tensor(<Tensor>)\n",
        "                            # I have labels of same length --> this should be no problem for Tensor\n",
        "                            local_labels = torch.stack(local_labels)\n",
        "                            # print(\"Labels:\")\n",
        "                            # print(local_synsets)\n",
        "        #                     print(\"Labels\")\n",
        "        #                     print(type(local_labels), len(local_labels), type(local_labels[0]))\n",
        "        #                     print(local_labels)\n",
        "\n",
        "                            # Transfer to GPU\n",
        "                            local_batch, local_labels = local_batch.to(self.device), local_labels.to(self.device)\n",
        "                            # print(\"Local batch and label after sending them to GPU\")\n",
        "                            # print(\"local batch GPU nb: \", local_batch.get_device())\n",
        "                            # print(\"local label GPU nb: \", local_labels.get_device())\n",
        "\n",
        "                            # Model computations\n",
        "                            # out outputs the indices of wordnet database\n",
        "                            out = self.model(local_batch)\n",
        "                            # print(\"out\", out.get_device())\n",
        "\n",
        "                            # During validation and testing, I want to be less strict.\n",
        "                            # So, if a point resides within the label sphere, the sense is correctly identified.\n",
        "                            loss = geometric_loss(out, local_labels, include_r=True)\n",
        "                            # print(\"loss\", loss.get_device())\n",
        "\n",
        "                            vloss_sum += loss.item()                  \n",
        "\n",
        "                            validation_loss = vloss_sum / len(local_batch)\n",
        "                            history['validation_loss'].append(validation_loss)\n",
        "                            print(history[\"validation_loss\"])\n",
        "#                             print(len(history['validation_loss']))\n",
        "\n",
        "#                             correct_sense_batch = 0\n",
        "# #                             print(\"Initializing the corrext sense batch = {}\".format(correct_sense_batch))\n",
        "\n",
        "#                             true_pred = []\n",
        "#                             # predicted_synsets = []\n",
        "\n",
        "#                             for i, word_tag in enumerate(out):\n",
        "#                                 #print(\"I am in the word tag loop : i = \", i)\n",
        "# #                                 print(\"+\"*150)\n",
        "# #                                 print(\"word_tag = \", word_tag.size())\n",
        "# #                                 print(word_tag)\n",
        "# #                                 print(\"+\"*150)\n",
        "\n",
        "\n",
        "#                                 vindices, vmat, vsyn = vicinity_matrix(spatial_params=word_tag,\n",
        "#                                                                target_vocab=target_vocab,\n",
        "#                                                                spatial_tags=spatial_tags, \n",
        "#                                                                k=k, device=self.device)\n",
        "#                                 # print(\"Vicinity Matrix-Synsets: {}\".format(vmat))\n",
        "#                                 # print(\"vmat\", vmat.get_device())\n",
        "#                                 # print(\"I passed the vicinity_matrix function\")\n",
        "\n",
        "#                                 #numba_type_indices = numba.typeof(np.array(k, dtype=np.int64))\n",
        "#                                 numba_indices = numba.typed.Dict.empty(\n",
        "#                                     key_type=numba.core.types.unicode_type,\n",
        "#                                     value_type=numba.int64[:],\n",
        "#                                     )\n",
        "#                                 # The typed-dict can be used from the interpreter.\n",
        "#                                 for key, value in vindices.items():\n",
        "#                                   # print(\"The Value\", type(value.cpu().detach().numpy()), value.cpu().detach().numpy())\n",
        "#                                   # print(numba.typeof(value.cpu().detach().numpy()))\n",
        "#                                     numba_indices[key] = np.asarray(value.cpu().detach().numpy(), dtype='i8')\n",
        "#                                 #print(\"numba indices\", numba_indices)\n",
        "#                                 #numba_indices['posx'] = np.asarray([1, 0.5, 2], dtype='f8')                                \n",
        "\n",
        "\n",
        "#                                 in_vic = label_in_vicinity(vicinity_matrix=vmat.cpu().detach().numpy(), #vicinity_synsets=vsyn,\n",
        "#                                                            vicinity_indices=numba_indices,\n",
        "#                                                            target_vocab=target_vocab, \n",
        "#                                                            spatial_tags=spatial_tags, \n",
        "#                                                            #true_label=local_labels[i].cpu().detach().numpy()\n",
        "#                                                            true_label_idx = local_idx\n",
        "#                                                            )\n",
        "                                \n",
        "#                                 # print(\"I passed the label_in_vicinity function\")\n",
        "#                                 # print(\"in_vic?\", in_vic)\n",
        "#                                 # print(\"pred_syn\", pred_syn)\n",
        "\n",
        "#                                 true_pred.append(in_vic)\n",
        "#                                 # predicted_synsets.append(pred_syn)\n",
        "                                \n",
        "#                                 print(\"In Vicinity? --> {}\".format(in_vic))\n",
        "# #                                 print(\"Predicted synsets --> {}\".format(pred_syn))\n",
        "\n",
        "#                                 if in_vic==True:\n",
        "#                                     correct_sense += 1\n",
        "#                                     correct_sense_batch += 1\n",
        "\n",
        "#                             # print(true_pred)\n",
        "#                             # print(predicted_synsets)\n",
        "                        \n",
        "#                             batch_acc = correct_sense_batch / len(local_batch)\n",
        "#                             history[\"sense_accuracy\"].append(batch_acc)\n",
        "# #                             print(\"correct sense batch ({}) / local_batch ({}) = {}\".format(correct_sense_batch, len(local_batch), batch_acc))\n",
        "\n",
        "\n",
        "                        # t1 = time.time()\n",
        "                        # print(f'Epoch {epoch+1}: train loss = {train_loss:.4f}, batch accuracy: {batch_acc:.4f}, time = {t1-t0:.4f} (s)')\n",
        "            t1 = time.time()\n",
        "            print(f'Epoch {epoch+1}: train loss = {train_loss:.4f}, time = {t1-t0:.4f} (s)')\n",
        "\n",
        "\n",
        "                # sense_accuracy = correct_sense / nb_words_validation * 100\n",
        "\n",
        "                # print(f\"The sense accuracy on the validation set is {sense_accuracy:.3f}%\")   #.format(sense_accuracy * 100))\n",
        "                \n",
        "        # # **************************************************************************************************************\n",
        "        # # Plot Histogram \n",
        "        # # **************************************************************************************************************\n",
        "        # data1 = history[\"train_loss\"] \n",
        "        # data2 = history[\"sense_accuracy\"]\n",
        "\n",
        "        # fig, ax1 = plt.subplots()\n",
        "\n",
        "        # color = 'tab:red'\n",
        "        # ax1.set_xlabel('time (s)')\n",
        "        # ax1.set_ylabel('loss', color=color)\n",
        "        # ax1.plot(data1, color=color)\n",
        "        # ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "        # ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "        # color = 'tab:blue'\n",
        "        # ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n",
        "        # ax2.plot(data2, color=color)\n",
        "        # ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "        # fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "        # plt.show()\n",
        "        print(history)\n",
        "\n",
        "        return history\n",
        "    \n",
        "    \n",
        "    # assuming the sentence is already splitted into tokens, e.g. ['fall', 'in', 'catastrophes']\n",
        "    def test(self, testing_data, path, data, batch_size, num_workers, target_vocab, spatial_tags, k=5, shuffle=True):\n",
        "        \n",
        "        if num_workers > 0:\n",
        "          pin_memory = True\n",
        "        else:\n",
        "          pin_memory = False\n",
        "\n",
        "        # parameters\n",
        "        params = {'batch_size': batch_size, #64,\n",
        "                  'shuffle': shuffle,\n",
        "                  'collate_fn': lambda x: x,\n",
        "                  'num_workers': num_workers, #6} #set 0 if training on Windows machine\n",
        "                  'pin_memory': pin_memory}\n",
        "        \n",
        "        # Training and validation data generators\n",
        "        testing_set = Dataset(testing_data, path)\n",
        "        testing_generator = DataLoader(testing_set, **params)\n",
        "        \n",
        "        # ------\n",
        "        # Count words in sentence to calculate accuracy\n",
        "        # ------\n",
        "        nb_words_testing = 0\n",
        "\n",
        "        for batch in testing_generator:\n",
        "            for sentence, label, syn, idx in batch:\n",
        "                nb_words_testing += len(sentence)\n",
        "                \n",
        "        # --------------------------\n",
        "        VOCAB, weights_matrix = load_vocab(data, embed_size=embed_size)\n",
        "\n",
        "\n",
        "        # ---------------------------  \n",
        "        # testing\n",
        "        # ---------------------------\n",
        "        correct_sense = 0\n",
        "        sense_accuracy = 0\n",
        "        \n",
        "        t0 = time.time()\n",
        "\n",
        "        # set model to eval mode to ignore updating the weights of the model\n",
        "        self.model.eval()\n",
        "\n",
        "        # do not calculate gradients while evaluating\n",
        "        with torch.set_grad_enabled(False):\n",
        "\n",
        "            for batch in testing_generator:\n",
        "                #print(\"Batches for testing\")\n",
        "                #print(\"#\" * 100)\n",
        "\n",
        "                for local_batch, local_labels, local_synsets, local_idx in batch:\n",
        "\n",
        "                    # Transform list(<string>) to Tensor(<Tensor>)\n",
        "                    print(\"Input Sentence\")\n",
        "                    print(local_batch)\n",
        "                    input_words = local_batch\n",
        "                    local_batch = numericalize(local_batch, VOCAB)\n",
        "#                     print(type(local_batch), local_batch)\n",
        "\n",
        "                    extract_labels = spatial_tags[local_idx]\n",
        "                    local_labels = [torch.tensor(lab) for lab in extract_labels]\n",
        "\n",
        "\n",
        "\n",
        "                    # Transform List(<Tensor>) to Tensor(<Tensor>)\n",
        "                    # I have labels of same length --> this should be no problem for Tensor\n",
        "                    local_labels = torch.stack(local_labels)\n",
        "                    print(\"Labels:\")\n",
        "                    print(local_synsets)\n",
        "                    #print(\"Labels\")\n",
        "                    #print(type(local_labels), len(local_labels), type(local_labels[0]))\n",
        "                    #print(local_labels)\n",
        "\n",
        "                    # Transfer to GPU\n",
        "                    local_batch, local_labels = local_batch.to(self.device), local_labels.to(self.device)\n",
        "\n",
        "                    # Model computations\n",
        "                    # out outputs the indices of wordnet database\n",
        "                    out = self.model(local_batch)\n",
        "\n",
        "                    # During validation and testing, I want to be less strict.\n",
        "                    # So, if a point resides within the label sphere, the sense is correctly identified.\n",
        "                    loss = geometric_loss(out, local_labels, include_r=True)\n",
        "\n",
        "                    vloss_sum += loss.item()                  \n",
        "\n",
        "                    validation_loss = vloss_sum / len(local_batch)\n",
        "                    history['testing_loss'].append(validation_loss)\n",
        "#                             print(history)\n",
        "#                             print(len(history['validation_loss']))\n",
        "\n",
        "                    correct_sense_batch = 0\n",
        "#                             print(\"Initializing the corrext sense batch = {}\".format(correct_sense_batch))\n",
        "\n",
        "                    true_pred = []\n",
        "                    #predicted_synsets = []\n",
        "\n",
        "                    for i, word_tag in enumerate(out):\n",
        "                      \n",
        "                        vindices, vmat, vsyn = vicinity_matrix(spatial_params=word_tag,\n",
        "                                                               target_vocab=target_vocab,\n",
        "                                                               spatial_tags=spatial_tags, \n",
        "                                                               k=k, device=self.device)\n",
        "                      # print(\"Vicinity Matrix-Synsets: {}\".format(vmat))\n",
        "                      # print(\"vmat\", vmat.get_device())\n",
        "                      # print(\"I passed the vicinity_matrix function\")\n",
        "\n",
        "                      #numba_type_indices = numba.typeof(np.array(k, dtype=np.int64))\n",
        "                        numba_indices = numba.typed.Dict.empty(\n",
        "                            key_type=numba.core.types.unicode_type,\n",
        "                            value_type=numba.int64[:],\n",
        "                            )\n",
        "                      # The typed-dict can be used from the interpreter.\n",
        "                        for key, value in vindices.items():\n",
        "                          # print(\"The Value\", type(value.cpu().detach().numpy()), value.cpu().detach().numpy())\n",
        "                          # print(numba.typeof(value.cpu().detach().numpy()))\n",
        "                            numba_indices[key] = np.asarray(value.cpu().detach().numpy(), dtype='i8')\n",
        "                        #print(\"numba indices\", numba_indices)\n",
        "                        #numba_indices['posx'] = np.asarray([1, 0.5, 2], dtype='f8')                                \n",
        "\n",
        "\n",
        "                        in_vic = label_in_vicinity(vicinity_matrix=vmat.cpu().detach().numpy(), #vicinity_synsets=vsyn,\n",
        "                                                    vicinity_indices=numba_indices,\n",
        "                                                    target_vocab=target_vocab, \n",
        "                                                    spatial_tags=spatial_tags, \n",
        "                                                    #true_label=local_labels[i].cpu().detach().numpy()\n",
        "                                                    true_label_idx = local_idx\n",
        "                                                    )\n",
        "                        \n",
        "                              \n",
        "                        # print(\"In Vicinity? --> {}\".format(in_vic))\n",
        "                        # print(\"Predicted synsets --> {}\".format(pred_syn))\n",
        "            \n",
        "                        true_pred.append(in_vic)\n",
        "                        #predicted_synsets.append(pred_syn)\n",
        "                        \n",
        "\n",
        "                        if in_vic:\n",
        "                            correct_sense += 1\n",
        "                            correct_sense_batch += 1\n",
        "\n",
        "                    #print(true_pred)\n",
        "                    #print(predicted_synsets)\n",
        "                    \n",
        "                    batch_acc = correct_sense_batch / len(local_batch)\n",
        "                    history[\"sense_accuracy\"].append(batch_acc)\n",
        "#                             print(\"correct sense batch ({}) / local_batch ({}) = {}\".format(correct_sense_batch, len(local_batch), batch_acc))\n",
        "\n",
        "                    \n",
        "                t1 = time.time()\n",
        "                print(f'batch accuracy: {batch_acc:.4f}, time = {t1-t0:.4f} (s)')\n",
        "\n",
        "\n",
        "        sense_accuracy = correct_sense / nb_words_validation * 100\n",
        "\n",
        "        print(f\"The sense accuracy on the testing set is {sense_accuracy:.3f}%\") #.format(sense_accuracy * 100))\n",
        "\n",
        "        return history\n",
        "\n",
        "        \n",
        "        \n",
        "    \n",
        "    def tag(self, sentence, embed_size, target_vocab, spatial_tags, k):\n",
        "        print(\"Initial Input: \", sentence)\n",
        "        \n",
        "        if isinstance(sentence, str):\n",
        "            # preprocess the sentence, such that the lemmatized sentence is returned\n",
        "            lemm_sentence = preprocess(sentence)\n",
        "            tokens = list(map(lambda x: x[0], lemm_sentence))\n",
        "            \n",
        "        if isinstance(sentence, list):\n",
        "            lst2str = \" \".join(sentence)\n",
        "            lemm_sentence = preprocess(lst2str)\n",
        "            tokens = list(map(lambda x: x[0], lemm_sentence))\n",
        "            \n",
        "            \n",
        "        \n",
        "        N = len(tokens)\n",
        "        tags = '?' * N\n",
        "        print(\"Lemmatized Sentence: \", tokens)\n",
        "        \n",
        "        #print(tags)\n",
        "        \n",
        "        data = tokens\n",
        "        \n",
        "        # words embeddings\n",
        "        vocab, wmat = load_vocab(data, embed_size)\n",
        "        \n",
        "        # numericalize words\n",
        "        num_data = numericalize(data, vocab)\n",
        "        \n",
        "        num_data = num_data.to(self.device)\n",
        "        \n",
        "        out = self.model(num_data)\n",
        "        \n",
        "        distances = []\n",
        "        predicted_indices = []\n",
        "\n",
        "        for i, word_tag in enumerate(out):\n",
        "\n",
        "            vindices, vmat, vsyn = vicinity_matrix(spatial_params=word_tag,\n",
        "                                           target_vocab=target_vocab,\n",
        "                                           spatial_tags=spatial_tags, k=k, device=self.device)\n",
        "#                                 print(\"Vicinity Matrix-Synsets: {}\".format(vsyn))\n",
        "             \n",
        "            # print(\"v indices\", vindices, vindices.values()[0].cpu().detach().numpy())\n",
        "            # numpy_idx = []\n",
        "            # for idx in vindices.values():\n",
        "            #     # idx is tensor \n",
        "            #     idx_npy = idx.cpu().detach().numpy\n",
        "  \n",
        "\n",
        "            predicted_indices.append(vindices)\n",
        "            #predicted_synsets.append(target_vocab[vindices.values()[0].cpu().detach().numpy()])\n",
        "    \n",
        "            distances.append(vsyn)\n",
        "            #distances.append(decode_key(vsyn.keys(), vmat))\n",
        "            \n",
        "        # for i in range(N):\n",
        "        #     print(data[i], \"\\t\", tags[i], \"\\t\", predicted_indices[i].items(), distances[i].items())\n",
        "        #     print()\n",
        "            \n",
        "        \n",
        "        return tokens, predicted_indices, distances\n",
        "\n",
        "        \n",
        "\n",
        "     "
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yT4POprfYM9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin Training"
      ],
      "metadata": {
        "id": "oNXr_LtJxmqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# superficial_splittings = splittings #[\"train\"][:20]\n",
        "# superficial_splittings[\"train\"] = superficial_splittings[\"train\"][:10]\n",
        "# superficial_splittings[\"validate\"] = superficial_splittings[\"validate\"][:5]"
      ],
      "metadata": {
        "id": "Qu3rfn8coJb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# superficial_splittings"
      ],
      "metadata": {
        "id": "VbAYxRI_5pfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "cuda\n",
            "[['necessary', 'means', 'know-how', 'authority'], ['necessary.a.01', 'means.n.01', 'know-how.n.01', 'authority.n.01'], [tensor([5.0801e+04, 1.3514e+05, 2.5010e+01, 6.4176e+04, 9.0000e+01, 5.0000e-01]), tensor([7.9562e+04, 1.1174e+05, 9.8310e+01, 9.8013e+04, 0.0000e+00, 1.8500e+01]), tensor([1.7459e+05, 1.4268e+05, 1.0717e+02, 7.1890e+04, 0.0000e+00, 1.0650e+02]), tensor([9.4484e+04, 3.7587e+04, 1.0434e+02, 1.9497e+05, 0.0000e+00, 7.5000e+00])], [50801, 79562, 174594, 94484]]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ...\n",
            "Validation ...\n",
            "Epoch 1: train loss = 171629.6547, time = 238.7764 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 2: train loss = 57209.9195, time = 235.8736 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 3: train loss = 42907.4344, time = 237.1574 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 4: train loss = 57209.8469, time = 238.5709 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 5: train loss = 28604.9387, time = 236.8463 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 6: train loss = 171629.6845, time = 238.6992 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 7: train loss = 57209.9014, time = 237.4144 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 8: train loss = 171629.6492, time = 238.5482 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 9: train loss = 42907.3877, time = 239.2345 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 10: train loss = 28604.9440, time = 221.5784 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 11: train loss = 171629.6021, time = 204.0968 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 12: train loss = 57209.8598, time = 208.4226 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 13: train loss = 28604.9451, time = 203.8295 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 14: train loss = 42907.4127, time = 204.1902 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 15: train loss = 171629.6336, time = 204.5541 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 16: train loss = 171629.6145, time = 205.1260 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 17: train loss = 171629.6750, time = 204.4626 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 18: train loss = 171629.5660, time = 203.9860 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 19: train loss = 42907.4081, time = 204.5081 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 20: train loss = 17162.9746, time = 206.2694 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 21: train loss = 171629.6692, time = 189.6060 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 22: train loss = 171629.6743, time = 212.6912 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 23: train loss = 42907.4053, time = 207.8900 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 24: train loss = 57209.8832, time = 207.7934 (s)\n",
            "Training ...\n",
            "Validation ...\n",
            "Epoch 25: train loss = 171629.6334, time = 205.7377 (s)\n"
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "#torch.backends.cudnn.benchmark = True\n",
        "\n",
        "#def train(self, batch_size: int, num_workers: int, max_epochs: int, \n",
        "              # splittings: dict, path2data: str, data: list, embed_size: int,\n",
        "              # target_vocab: list, spatial_tags: list,\n",
        "              # k=5,\n",
        "              # d_model=300, d_hid=200, nlayers=2, nhead=2, dropout=0.2,\n",
        "              # lr=5.0, gamma=0.95,\n",
        "              # shuffle=True)\n",
        "\n",
        "T = RegTagger(use_cuda=use_cuda, device=device)\n",
        "\n",
        "train_history = T.train(batch_size=64, \n",
        "                        num_workers=0, \n",
        "                        max_epochs=8, \n",
        "                        splittings=splittings, \n",
        "                        path2data=resources_path + pwngc_path + \"/indexed_pwngc_id.pt\", \n",
        "                        data=list(datasetID.values()), \n",
        "                        embed_size=300, \n",
        "                        target_vocab=target_VOCAB, \n",
        "                        spatial_tags=SPATIAL_TAGS,\n",
        "                        d_model=300, d_hid=200, nlayers=8, nhead=4, dropout=0.2,\n",
        "                        lr=1e-2, gamma=0.95, \n",
        "                        shuffle=True\n",
        "                        )"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5Ne1kewYM9h",
        "outputId": "811ceb76-16a6-44d5-ffe3-ce055996d84f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "xnYVwQ7qkp1f",
        "outputId": "68a225be-c00e-4daf-f70e-5f10bc13e170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d2f1960a1e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cfTzYIUAkpxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store history in a pickle\n",
        "file4train_history = resources_path + pwngc_path + \"/train_hist.pkl\"\n",
        "\n",
        "open_file = open(file4train_history, \"wb\")\n",
        "pickle.dump(train_history, open_file)\n",
        "open_file.close()\n"
      ],
      "metadata": {
        "id": "uD7nEfCX871Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "9ecb95e5-6d71-4b16-ca5b-a9282f387171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-88ef637a76cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# store history in a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfile4train_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresources_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpwngc_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/train_hist.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopen_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile4train_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'resources_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Input:  ['Hundred', 'babies', 'are', 'one', 'years', 'old', '.']\n",
            "Lemmatized Sentence:  ['hundred', 'baby', 'one', 'year', 'old']\n",
            "hundred\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-9def5e84b963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Hundred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'babies'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'are'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'one'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'years'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'old'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentag_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentag_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_VOCAB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSPATIAL_TAGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdecode_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentag_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentag_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-3f3a9f64adaa>\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, sentence, embed_size, target_vocab, spatial_tags, k)\u001b[0m\n\u001b[1;32m    529\u001b[0m             vindices, vmat, vsyn = vicinity_matrix(spatial_params=word_tag,\n\u001b[1;32m    530\u001b[0m                                            \u001b[0mtarget_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_vocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                                            spatial_tags=spatial_tags, k=k, device=self.device)\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;31m#                                 print(\"Vicinity Matrix-Synsets: {}\".format(vsyn))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-51b836431ce7>\u001b[0m in \u001b[0;36mvicinity_matrix\u001b[0;34m(spatial_params, target_vocab, spatial_tags, k, device)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mdist_spheres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mdist_pt_sphere\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt_sphere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mdist_pts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-29014946c2b5>\u001b[0m in \u001b[0;36mdistance_loss\u001b[0;34m(pred_pt, original_pt, include_r, pt_sphere, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_pt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mpred_sense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo2point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0morig_sense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo2point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-29014946c2b5>\u001b[0m in \u001b[0;36mcoo2point\u001b[0;34m(coo)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ml_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbeta_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbeta_i_rad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "sentence = ['Hundred', 'babies', 'are', 'one', 'years', 'old', '.']\n",
        "tokens, sentag_idx, sentag_dist = T.tag(sentence, 300, target_VOCAB, SPATIAL_TAGS, 5)\n",
        "decode_tag(tokens, sentag_idx, sentag_dist)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mByqtQACYM9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "dcd498c4-990f-4ef8-ad1a-a876caa3d36f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L4Ks3zty5znv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "regressor_pwngc_index_based.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yG45YqPiOwtZ",
        "AaNWxx1ZYM9J",
        "JXSQufUkYM9P",
        "L6PSPtIAvhvc",
        "4swbnCh2Cc7t",
        "owbftETCr1eR",
        "iZsdSJmaYM9R",
        "EkIQUo3sYM9U",
        "sp-hIJf-YM9Z",
        "buL4R4UuYM9c",
        "0vR0knpCt5zf"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}